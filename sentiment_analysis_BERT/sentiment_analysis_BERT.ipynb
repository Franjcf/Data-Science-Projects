{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNHUPu9nGTk"
      },
      "source": [
        "# Fine-Tuning BERT for Sentiment Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVt77lEPnGTo"
      },
      "source": [
        "## Notes on the data\n",
        "\n",
        "The data used in this study consists of 3000 customer reviews labeled into two classes: where label ”1” refers to a positive review and label ”0” refers to a negative review. For the purposes of this study, the data set was separated into a training set of 2400 samples and a testing set of 600 samples. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0gTAM3mnGTp"
      },
      "source": [
        "## Other Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAzDBjnKnGTq"
      },
      "source": [
        "The attached \"DataAnalysisScript.py\" script should be run within the same directory as the \"Words\" directory. This directory contains the vocabulary and bag of words representations obtained from labeled amazon reviews (test.txt and train.txt) using the accompaning \"prepossessingSentences.py\" script. There is no need to said code here since I have already generated all the neccesary vocabulary files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSKesYfFnGTr"
      },
      "source": [
        "## Loading Main libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TnQjpTonGTr"
      },
      "source": [
        "# Loading basic libraries\n",
        "import warnings #prevent \"future warning\" errors\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "import re\n",
        "\n",
        "#loading sklearn libraries\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score,average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr_sBPuyuYsD"
      },
      "source": [
        "!pip install tensorflow_datasets\n",
        "!pip install -U tensorflow-text\n",
        "!pip install -q tf-models-official\n",
        "!pip install --upgrade plotly\n",
        "!pip install -U kaleido"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrshnCpuaT3"
      },
      "source": [
        "#loading tensorflow libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5c1nsETnGTs"
      },
      "source": [
        "# Data Proccesing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btbimMPznGTs"
      },
      "source": [
        "## Loading data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn_mJ7L9py_3",
        "outputId": "65f8e3af-22af-45ae-f4ac-3d5d166af4c2"
      },
      "source": [
        "#mounting google colab drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/',force_remount=True)\n",
        "\n",
        "# defining directory to store files\n",
        "path = \"/gdrive/MyDrive/Colab\\ Notebooks/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBtqdpdqyhLM"
      },
      "source": [
        "# defining function to read included txt files. \n",
        "def read_files(path):\n",
        "\n",
        "  #initializing lists\n",
        "  labels = []\n",
        "  strings = []    \n",
        "  index = []\n",
        "\n",
        "  f = open(path, 'r')\n",
        "  lines = f.readlines()\n",
        "\n",
        "  for line in lines:\n",
        "\n",
        "    #separating columns of data into indexes, strings, and labels\n",
        "    labels.append(line.rsplit()[-1])\n",
        "    index.append(line.rsplit()[0])\n",
        "    string = line\n",
        "    string = ' '.join(string.rsplit()[1:-1])\n",
        "\n",
        "    #adding to list\n",
        "    strings.append(string)\n",
        "\n",
        "  dictionary = {'Sentences':strings, 'Labels':labels}\n",
        "  df = pd.DataFrame(dictionary, index = index)\n",
        "  df[\"Labels\"] = pd.to_numeric(df[\"Labels\"])\n",
        "  df = df.sample(frac=1)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "GLfMBNViyKQ7",
        "outputId": "9072bd79-b71a-4cf6-feb9-398a571f2c9d"
      },
      "source": [
        "#reading data\n",
        "train = read_files(\"gdrive/MyDrive/Colab Notebooks/Words/train.txt\")\n",
        "test = read_files(\"gdrive/MyDrive/Colab Notebooks/Words/test.txt\")\n",
        "\n",
        "#looking at data\n",
        "print(\"training data shape: \", train.shape)\n",
        "print(\"testing data shape: \", test.shape)\n",
        "\n",
        "train.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data shape:  (2400, 2)\n",
            "testing data shape:  (600, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentences</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>I felt as though her going to Ireland did abso...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>This is essentially a communications tool that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>It shouldn't take 30 min for pancakes and eggs.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>It's very attractive and appears to be of good...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>I do love sushi, but I found Kabuki to be over...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>I would recommend this.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2344</th>\n",
              "      <td>The cow tongue and cheek tacos are amazing.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>I'm glad the film didn't go for the most obvio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>The character developments also lacked in depth.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>Considering the relations off screen between T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentences  Labels\n",
              "1000  I felt as though her going to Ireland did abso...       0\n",
              "77    This is essentially a communications tool that...       0\n",
              "1759    It shouldn't take 30 min for pancakes and eggs.       0\n",
              "530   It's very attractive and appears to be of good...       1\n",
              "1967  I do love sushi, but I found Kabuki to be over...       0\n",
              "513                             I would recommend this.       1\n",
              "2344        The cow tongue and cheek tacos are amazing.       1\n",
              "1230  I'm glad the film didn't go for the most obvio...       1\n",
              "937    The character developments also lacked in depth.       0\n",
              "1050  Considering the relations off screen between T...       0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1BYohlT_VUQ",
        "outputId": "abf31aba-64d1-4a94-8233-976843567c03"
      },
      "source": [
        "# converting data to tf dataset tensor \n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 2400\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train[\"Sentences\"], train[\"Labels\"]))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test[\"Sentences\"], test[\"Labels\"]))\n",
        "\n",
        "#Shuffling and dividing training data into batches\n",
        "train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "#checking if conversion was done OK\n",
        "for batch in train_ds.take(1):\n",
        "  for row in batch[:][0][:2]:\n",
        "    print(row)\n",
        "\n",
        "  for label in batch[:][1][:2]:\n",
        "    print(label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'This is the number one best TH game in the series.', shape=(), dtype=string)\n",
            "tf.Tensor(b'Same problem as others have mentioned.', shape=(), dtype=string)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAohxzJDqSIm",
        "outputId": "9de49cda-5325-409d-ca5d-8f72d96e3c4a"
      },
      "source": [
        "#alternativley, converting data to numpy array\n",
        "\n",
        "train_x = train[\"Sentences\"].to_numpy()\n",
        "train_y = train[\"Labels\"].to_numpy()\n",
        "\n",
        "test_x = test[\"Sentences\"].to_numpy()\n",
        "test_y = test[\"Labels\"].to_numpy()\n",
        "\n",
        "#checking if conversion was done OK\n",
        "for i in range(10):\n",
        "  print(train_x[i],train_y[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I felt as though her going to Ireland did absolutely nothing whatsoever. 0\n",
            "This is essentially a communications tool that does not communicate. 0\n",
            "It shouldn't take 30 min for pancakes and eggs. 0\n",
            "It's very attractive and appears to be of good quality. 1\n",
            "I do love sushi, but I found Kabuki to be over-priced, over-hip and under-services. 0\n",
            "I would recommend this. 1\n",
            "The cow tongue and cheek tacos are amazing. 1\n",
            "I'm glad the film didn't go for the most obvious choice, as a lesser film certainly would have. 1\n",
            "The character developments also lacked in depth. 0\n",
            "Considering the relations off screen between Taylor and Stanwyck, it was surprising how little chemistry there was on screen between the two of them. 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsWfxcr1DfFd"
      },
      "source": [
        "## Choosing BERT model to create embeddings\n",
        "\n",
        "The included dictonaries are included for easy access to alternative models \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glV0c9R9AtvN"
      },
      "source": [
        "#defining dictionaries\n",
        "map_name_to_handle = {\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {   \n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qor16ntD_fb",
        "outputId": "1c563a6b-416a-4e5d-a1b5-61c2018a94d9"
      },
      "source": [
        "#choosing model\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
        "\n",
        "#finding related preproccesors and encoders\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "#loading preproccesor model\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess,name='preprocess')\n",
        "\n",
        "#choosing encoder model\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder,trainable=True,name='encoder')\n",
        "\n",
        "#printing choices\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_n1FPGFKiW"
      },
      "source": [
        "# Testing pre-proccesing and encoding the data \n",
        "(code modified from https://www.tensorflow.org/text/tutorials/classify_text_with_bert?version=nightly)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca3srVEnEGUp",
        "outputId": "2e06ff2d-6e3a-49e9-b41a-c019f09067ea"
      },
      "source": [
        "#testing pre-proccesing the data\n",
        "temp = [\"I will never buy this item again!\"]\n",
        "\n",
        "temp_preprocces = bert_preprocess_model(temp)\n",
        "\n",
        "print(f'Keys       : {list(temp_preprocces.keys())}')\n",
        "print(f'Shape      : {temp_preprocces[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {temp_preprocces[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {temp_preprocces[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {temp_preprocces[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 1045 2097 2196 4965 2023 8875 2153  999  102    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKV0zxRTDER1",
        "outputId": "9218fc41-eec6-4a67-e856-4dae43e70a24"
      },
      "source": [
        "#testing encoding the data\n",
        "temp_results = bert_model(temp_preprocces)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{temp_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{temp_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{temp_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{temp_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.66916597  0.99434406 -0.53204316  0.05034159  0.7883574   0.608201\n",
            "  0.98778874 -0.99891245 -0.65899855 -0.9997528  -0.02892545 -0.9816345 ]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.03490189  0.22657266  0.4805516  ... -0.32216778  1.4762723\n",
            "   0.24345133]\n",
            " [-0.14663199  1.4872807  -0.28279895 ... -0.6117      0.8384829\n",
            "  -0.04838954]\n",
            " [-0.41417813  0.6729794  -1.4870961  ... -0.5815437   0.1650127\n",
            "   1.2022147 ]\n",
            " ...\n",
            " [-0.1594646   0.294144    0.7829197  ... -0.8159708   1.5213435\n",
            "   0.18805006]\n",
            " [-0.07993805 -0.4246581   0.04261737 ...  0.09465174  0.9633994\n",
            "   0.3636647 ]\n",
            " [-0.1249979  -0.27277327 -0.08296376 ... -0.00683095  1.0517676\n",
            "   0.20736562]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc4PU0EfFfmo"
      },
      "source": [
        "It looks like we are able to encode our test sentence pretty well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBnx6NCHLg9"
      },
      "source": [
        "# Building the Model Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkXhAbS6Ko-o"
      },
      "source": [
        "## Creating pipeline to create classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB4RljwdFfP8"
      },
      "source": [
        "def classifier_pipeline(intermediate_layers,num_units):\n",
        "  \n",
        "  #defining input layer\n",
        "  input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='input')\n",
        "\n",
        "  #pre-proccesing the data\n",
        "  pre = bert_preprocess_model(input)\n",
        "\n",
        "  #encoding the data\n",
        "  encoded = bert_model(pre)\n",
        "  out = encoded[\"pooled_output\"]\n",
        "  #out = encoded[\"sequence_output\"]\n",
        "\n",
        "  #creating a neural network\n",
        "  nn = out\n",
        "  nn = tf.keras.layers.Dropout(0.1)(nn)\n",
        "\n",
        "  #intermediate layers\n",
        "  for i in range(intermediate_layers):\n",
        "    nn = tf.keras.layers.Dense(num_units, activation=\"relu\")(nn)\n",
        "    nn = tf.keras.layers.Dropout(0.1)(nn)\n",
        "\n",
        "  #classification layer\n",
        "  nn = tf.keras.layers.Dense(1, activation=None, name='classifier')(nn)\n",
        "\n",
        "  #returning built network:\n",
        "  return tf.keras.Model(input, nn)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zodXTcQ5KsWN"
      },
      "source": [
        "## Defining loss functions and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZulLdK2qI3f7"
      },
      "source": [
        "#creating loss function \n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metric = tf.metrics.BinaryAccuracy()\n",
        "\n",
        "#defining optimizer with tunable parameters\n",
        "epochs = 20\n",
        "sentences_per_epoch = 2400\n",
        "total_steps = epochs*sentences_per_epoch\n",
        "warmup_steps = int(0.1*total_steps)\n",
        "optimizer = optimization.create_optimizer(init_lr=3e-5,\n",
        "                                          num_train_steps=total_steps,\n",
        "                                          num_warmup_steps=warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO050WjHLh72"
      },
      "source": [
        "## Creating and compiling classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc4oZDuDLwKB",
        "outputId": "7706b83d-d326-4569-e0cd-efbb2279e65c"
      },
      "source": [
        "intermediate_layers = 1 #1\n",
        "num_units = 50\n",
        "model = classifier_pipeline(intermediate_layers=intermediate_layers, num_units=num_units)\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocess (KerasLayer)         {'input_type_ids': ( 0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "encoder (KerasLayer)            {'sequence_output':  28763649    preprocess[0][0]                 \n",
            "                                                                 preprocess[0][1]                 \n",
            "                                                                 preprocess[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           encoder[0][5]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           25650       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 50)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 1)            51          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 28,789,350\n",
            "Trainable params: 28,789,349\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ00r5ZMNBWC"
      },
      "source": [
        "## Training and Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0bl1Rdm28UG",
        "outputId": "5e32b878-aa0a-478e-bc97-d8cf5181efb7"
      },
      "source": [
        "his = model.fit(x = train_x, y = train_y, epochs = epochs, validation_data=(test_x,test_y)) #20"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "75/75 [==============================] - 42s 454ms/step - loss: 0.8983 - binary_accuracy: 0.4983 - val_loss: 0.8199 - val_binary_accuracy: 0.5017\n",
            "Epoch 2/20\n",
            "75/75 [==============================] - 34s 447ms/step - loss: 0.7834 - binary_accuracy: 0.5033 - val_loss: 0.7205 - val_binary_accuracy: 0.4900\n",
            "Epoch 3/20\n",
            "75/75 [==============================] - 33s 446ms/step - loss: 0.7068 - binary_accuracy: 0.5288 - val_loss: 0.6821 - val_binary_accuracy: 0.5500\n",
            "Epoch 4/20\n",
            "75/75 [==============================] - 33s 445ms/step - loss: 0.6699 - binary_accuracy: 0.5629 - val_loss: 0.6299 - val_binary_accuracy: 0.6150\n",
            "Epoch 5/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.6112 - binary_accuracy: 0.6379 - val_loss: 0.5723 - val_binary_accuracy: 0.7083\n",
            "Epoch 6/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.5647 - binary_accuracy: 0.6808 - val_loss: 0.5107 - val_binary_accuracy: 0.7400\n",
            "Epoch 7/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.5228 - binary_accuracy: 0.7229 - val_loss: 0.4497 - val_binary_accuracy: 0.7917\n",
            "Epoch 8/20\n",
            "75/75 [==============================] - 33s 443ms/step - loss: 0.4562 - binary_accuracy: 0.7871 - val_loss: 0.4000 - val_binary_accuracy: 0.8133\n",
            "Epoch 9/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.3959 - binary_accuracy: 0.8279 - val_loss: 0.3622 - val_binary_accuracy: 0.8383\n",
            "Epoch 10/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.3516 - binary_accuracy: 0.8508 - val_loss: 0.3332 - val_binary_accuracy: 0.8567\n",
            "Epoch 11/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.3228 - binary_accuracy: 0.8633 - val_loss: 0.3135 - val_binary_accuracy: 0.8633\n",
            "Epoch 12/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.2789 - binary_accuracy: 0.8925 - val_loss: 0.2966 - val_binary_accuracy: 0.8817\n",
            "Epoch 13/20\n",
            "75/75 [==============================] - 33s 445ms/step - loss: 0.2660 - binary_accuracy: 0.8967 - val_loss: 0.2852 - val_binary_accuracy: 0.8900\n",
            "Epoch 14/20\n",
            "75/75 [==============================] - 33s 445ms/step - loss: 0.2313 - binary_accuracy: 0.9096 - val_loss: 0.2898 - val_binary_accuracy: 0.8783\n",
            "Epoch 15/20\n",
            "75/75 [==============================] - 33s 445ms/step - loss: 0.2145 - binary_accuracy: 0.9250 - val_loss: 0.2836 - val_binary_accuracy: 0.8850\n",
            "Epoch 16/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.1830 - binary_accuracy: 0.9329 - val_loss: 0.2940 - val_binary_accuracy: 0.8950\n",
            "Epoch 17/20\n",
            "75/75 [==============================] - 33s 445ms/step - loss: 0.1683 - binary_accuracy: 0.9421 - val_loss: 0.2927 - val_binary_accuracy: 0.9050\n",
            "Epoch 18/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.1398 - binary_accuracy: 0.9571 - val_loss: 0.3059 - val_binary_accuracy: 0.9050\n",
            "Epoch 19/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.1139 - binary_accuracy: 0.9617 - val_loss: 0.3233 - val_binary_accuracy: 0.8900\n",
            "Epoch 20/20\n",
            "75/75 [==============================] - 33s 444ms/step - loss: 0.1043 - binary_accuracy: 0.9658 - val_loss: 0.3389 - val_binary_accuracy: 0.9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNIj1rihnGTu"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7hK5mOfkqGD",
        "outputId": "918b0768-fff7-4ad1-c733-6f70dec79b08"
      },
      "source": [
        "#model validation\n",
        "loss, accuracy  = model.evaluate(x=test_x, y = test_y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 4s 194ms/step - loss: 0.3389 - binary_accuracy: 0.9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "vDC0ZstaohPg",
        "outputId": "16983f31-9311-4a48-959f-e69dc178fa65"
      },
      "source": [
        "#plotting accuracy vs epochs\n",
        "acc = his.history['binary_accuracy']\n",
        "val_acc = his.history['val_binary_accuracy']\n",
        "x_axis = list(range(epochs))\n",
        "\n",
        "dimensions = {\"height\" : 500, \"width\" :1200}\n",
        "gridTemplate = {\"showgrid\":False,\n",
        "                  \"showline\":True,\n",
        "                  \"linecolor\":\"black\",\n",
        "                  \"linewidth\":3,\n",
        "                  \"ticks\":'inside'}\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=x_axis,y=acc,name=\"Train Accuracy\",line=dict(width=5)))\n",
        "fig.add_trace(go.Scatter(x=x_axis,y=val_acc,name = \"Validation Accuracy\",line=dict(width=5)))\n",
        "fig.update_xaxes(gridTemplate, title_text=\"Epochs\",automargin=True)\n",
        "fig.update_yaxes(gridTemplate, title_text=\"Accuracy\",automargin=True)\n",
        "fig.update_layout(dimensions,font=dict(color=\"black\",size=28))\n",
        "fig.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.4.2.min.js\"></script>                <div id=\"cbb5a497-2d15-4e77-9644-1896e29ca631\" class=\"plotly-graph-div\" style=\"height:500px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cbb5a497-2d15-4e77-9644-1896e29ca631\")) {                    Plotly.newPlot(                        \"cbb5a497-2d15-4e77-9644-1896e29ca631\",                        [{\"line\":{\"width\":5},\"name\":\"Train Accuracy\",\"type\":\"scatter\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.4983333349227905,0.503333330154419,0.5287500023841858,0.5629166960716248,0.6379166841506958,0.6808333396911621,0.7229166626930237,0.7870833277702332,0.82791668176651,0.8508333563804626,0.8633333444595337,0.8924999833106995,0.8966666460037231,0.909583330154419,0.925000011920929,0.9329166412353516,0.9420833587646484,0.9570833444595337,0.9616666436195374,0.965833306312561]},{\"line\":{\"width\":5},\"name\":\"Validation Accuracy\",\"type\":\"scatter\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.5016666650772095,0.49000000953674316,0.550000011920929,0.6150000095367432,0.7083333134651184,0.7400000095367432,0.7916666865348816,0.8133333325386047,0.8383333086967468,0.8566666841506958,0.8633333444595337,0.8816666603088379,0.8899999856948853,0.878333330154419,0.8849999904632568,0.8949999809265137,0.9049999713897705,0.9049999713897705,0.8899999856948853,0.9066666960716248]}],                        {\"font\":{\"color\":\"black\",\"size\":28},\"height\":500,\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"width\":1200,\"xaxis\":{\"automargin\":true,\"linecolor\":\"black\",\"linewidth\":3,\"showgrid\":false,\"showline\":true,\"ticks\":\"inside\",\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"automargin\":true,\"linecolor\":\"black\",\"linewidth\":3,\"showgrid\":false,\"showline\":true,\"ticks\":\"inside\",\"title\":{\"text\":\"Accuracy\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cbb5a497-2d15-4e77-9644-1896e29ca631');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E3MyvCn2rBm"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwADqc0hbwQr",
        "outputId": "580a21b4-6b0f-4dff-b31d-25d9966cc04f"
      },
      "source": [
        "#saving the model\n",
        "save_path = \"/content/gdrive/MyDrive/Colab Notebooks/Checkpoints/\"\n",
        "model.save(save_path+\"my_model\", include_optimizer=False,save_format='tf')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 310). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Colab Notebooks/Checkpoints/my_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Colab Notebooks/Checkpoints/my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdVlxesJ2mje"
      },
      "source": [
        "## Loading saved model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uThwLoIlNEZZ",
        "outputId": "f00e15de-dc40-4be1-97f4-1a7debd88f68"
      },
      "source": [
        "#loading the model\n",
        "loaded_model = tf.keras.models.load_model(save_path+\"my_model\")\n",
        "loaded_model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "loaded_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocess (KerasLayer)         {'input_type_ids': ( 0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "encoder (KerasLayer)            {'sequence_output':  28763649    preprocess[0][0]                 \n",
            "                                                                 preprocess[0][1]                 \n",
            "                                                                 preprocess[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           encoder[0][5]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           25650       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 50)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 1)            51          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 28,789,350\n",
            "Trainable params: 28,789,349\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcLi38IPnGTz"
      },
      "source": [
        "\n",
        "## Testing on my own sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7PFx9dxnGTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482dee06-2dd6-4f61-a6da-a3e7200d9dc1"
      },
      "source": [
        "testing_sentences = [\"I loved the product!\",\n",
        "                    \"Whoever thought of this is a genius\",\n",
        "                    \"It was ok\",\n",
        "                    \"The new appliance sucks\",\n",
        "                     \"Stay away from this\",\n",
        "                    \"I wont be buying this again\"]\n",
        "\n",
        "results = tf.sigmoid(model(tf.constant(testing_sentences)))\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.99598783]\n",
            " [0.92446333]\n",
            " [0.9475148 ]\n",
            " [0.01328045]\n",
            " [0.04641866]\n",
            " [0.05369261]], shape=(6, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiX3OrRW2Nil"
      },
      "source": [
        "It looks like classifier works great, giving positive reviews a high logit value and negative reviews low values. "
      ]
    }
  ]
}